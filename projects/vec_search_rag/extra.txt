Credentials

mongo atlas

Your current IP address (71.233.112.194) 

username
ebenezerasabre

 password
ieQJIQh08n271Wr9


2. Install your driver
Run the following on the command line
Note: Use appropriate Python 3 executable

python -m pip install "pymongo[srv]"



mongodb uri

mongodb+srv://ebenezerasabre:ieQJIQh08n271Wr9@cluster0.fmb7k.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0

open ai api key

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



3. Add your connection string into your application code

from pymongo.mongo_client import MongoClient
from pymongo.server_api import ServerApi

uri = "mongodb+srv://ebenezerasabre:ieQJIQh08n271Wr9@cluster0.fmb7k.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"

# Create a new client and connect to the server
client = MongoClient(uri, server_api=ServerApi('1'))

# Send a ping to confirm a successful connection
try:
    client.admin.command('ping')
    print("Pinged your deployment. You successfully connected to MongoDB!")
except Exception as e:
    print(e)
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
This is my code

# will generate the user interface and will allows us to perform
# quest against our data using atlast vector search and openai




from pymongo import MongoClient
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.document_loaders import DirectoryLoader
from langchain.llms import openai
from langchain.chains import retrieval_qa
import gradio as gr # for creating frontend
from gradio.themes.base import Base
import key_param


# we are going to get sample documents
# we will load 3 text from our directory using DirectoryLoader


client = MongoClient(key_param.MONGO_URI)
dbName = "langchain_demo"
collectionName = "collection_of_text_blobs"
collection = client[dbName][collectionName]

# get embeddings
embeddings = OpenAIEmbeddings(openai_api_key=key_param.openai_api_key)

# get vector
vectorStore = MongoDBAtlasVectorSearch.from_documents(collection, embeddings )


# from langchain.chains import retrieval_qa

# qa_chain = retrieval_qa.RetrievalQA(vector_store.as_retriever(), llm=openai.OpenAI(api_key=openai_api_key))


def query_data(query):
    docs = vectorStore.similarity_search(query, k=1)
    as_output = docs[0].page_content

    llm = openai(openai_api_key=key_param.openai_api_key, temperature=0)
    retriever = vectorStore.as_retriever()
    qa = retrieval_qa.RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retriever)
    # qa = retrieval_qa.from_chain_type(llm, chain_type="stuff", retriever=retriever)
    retriever_output = qa.run(query) #execute chain

    return as_output, retriever_output


with gr.Blocks(theme=Base(), title="Question Asnwering App using Vector Search + RAG") as demo:
    gr.Markdown( """# Question Answering App using Atlas Vector Search + RAG Architecture""")
    textbox = gr.Textbox(label="Enter your Question:")
    with gr.Row():
        button = gr.Button("Submit", variant="primary")
    with gr.Column():
        output1 = gr.Textbox(lines=1, max_lines=10, label="Output with just Atlas Vector Search (returns text field as is):")
        output2 = gr.Textbox(lines=1, max_lines=10, label="Output generated by changing Atlas vector search to Langchain's RetrievalQA + openAI LLM:)")

    button.click(query_data, textbox, outputs=[output1, output2])

demo.launch()
    
    
    
THis is my error:
    
python3 extract_info.py 
/home/ebenezer/Developer/machine_learning/projects/answer_app/extract_info.py:8: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import OpenAIEmbeddings

with new imports of:

>> from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings.openai import OpenAIEmbeddings
/home/ebenezer/Developer/machine_learning/projects/answer_app/extract_info.py:9: LangChainDeprecationWarning: Importing MongoDBAtlasVectorSearch from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import MongoDBAtlasVectorSearch

with new imports of:

>> from langchain_community.vectorstores import MongoDBAtlasVectorSearch
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.vectorstores import MongoDBAtlasVectorSearch
/home/ebenezer/Developer/machine_learning/projects/answer_app/extract_info.py:10: LangChainDeprecationWarning: Importing DirectoryLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:

>> from langchain.document_loaders import DirectoryLoader

with new imports of:

>> from langchain_community.document_loaders import DirectoryLoader
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.document_loaders import DirectoryLoader
/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import openai`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
/home/ebenezer/Developer/machine_learning/projects/answer_app/extract_info.py:28: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.
  embeddings = OpenAIEmbeddings(openai_api_key=key_param.openai_api_key)
Traceback (most recent call last):
  File "/home/ebenezer/Developer/machine_learning/projects/answer_app/extract_info.py", line 31, in <module>
    vectorStore = MongoDBAtlasVectorSearch.from_documents(collection, embeddings )
  File "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores/base.py", line 841, in from_documents
    texts = [d.page_content for d in documents]
TypeError: 'Collection' object is not iterable
    
    
    
  RAG with Atlas Vector Search, LangChain, OpenAI  
    
  Retrieval augmentation generation
  
 user sends query
 convert input query into a vector using openAI embeddings
 Perform atlas vectorsearch using langchain vector store
 
 retrieve similar document from mongodb based on the query vector
 
 define LLM using openai api
 
 retriever fetches documents relevant to our query
 LLM generate responses based on the documents retrieved and query
 finally execute chain.
    













import bs4
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

## INDEXING

#load documents
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)

docs = loader.load()

#Split
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)

#embed
vectorStore = chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

retriever = vectorStore.as_retriever()

### RETRIEVAL and GENERATION ###

#Prompt
prompt = hub.pull("rlm/rag-prompt")


#LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)



import os

os.environ['LANGCHAIN_TRACING_V2'] = 'true'
os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'
os.environ['LANGCHAIN_API_KEY'] = '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'
os.environ['LANGCHAIN_PROJECT'] = 'pr-cold-seat-7'
os.environ['openai_api_key'] = "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"



import bs4
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
# from langchain_community.vectorstores import chroma
from langchain.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

## INDEXING

#load documents
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)

docs = loader.load()

#Split
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)

#embed
vectorStore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

retriever = vectorStore.as_retriever()

### RETRIEVAL and GENERATION ###

#Prompt
prompt = hub.pull("rlm/rag-prompt")


#LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)




---------------------------------------------------------------------------
OpenAIError                               Traceback (most recent call last)
<ipython-input-20-db3a2a23ef94> in <cell line: 30>()
     28 
     29 #embed
---> 30 vectorStore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())
     31 
     32 retriever = vectorStore.as_retriever()

    [... skipping hidden 1 frame]

1 frames
/usr/local/lib/python3.10/dist-packages/openai/_client.py in __init__(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)
    103             api_key = os.environ.get("OPENAI_API_KEY")
    104         if api_key is None:
--> 105             raise OpenAIError(
    106                 "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
    107             )

OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable




1. What is your specific mission?

 I want to focus on technology and innovation since that is my expertise. I want to be the african face of tehnology. I would like to write about africans that are doing great things home or abroad in the technology sphere. Something that can inspire other africans.


2 Who is your target audience?
I am targeting young africans both home and abroad. Becuase it seems to me the problem of lost identity cut across.


3 What content or services will you offer initially?
I would like to start with blog and making videos about tech entrepreneurs, black scientist. I am thinking of incoorperating story telling since I am good at time. So i can make blog/video on historical figures or contemporary people.


4. How will you differentiate yourself from existing platforms?
I am not sure of existing platforms but probably there are. I think they might be specific but I want to be general and relatable


5. What is your long-term vision for the platform?

In the long term, I am looking at creating a business conglomerate the support african business especially in science and technology. I see myself as becoming the African face of technology

6. How will you monetize the platform?
Initially i have no idea how I can monitize it. Any suggestion might help. Probably If I am able to generate a huge social media following, I might get sponsorship deals.

7. Do you plan to involve external collaborators or sponsors?
If it comes to that, I would like to partner with companies who want to invest in africa. Promoting indegenous african businesses


9. What challenges do you foresee, and how will you overcome them?
Definitely Africa is a big continent so I am expecting difficulty in acceptance across. Also i see challenge in creating a big plat form that will be accepted by africans on the continent and in the diaspora.

10. What metrics will you use to measure success?
I am thinking the traffic and followers the platform can generate. Since people like stories, maybe good stories about current and old africans who have contributed/contributing to uplift the image of africa might help in it's adoption. But sincerely speaking I have not idea, any suggestion might help





Created a Content Management System to streamline HR operations and improve project oversight.
























import os
import uuid
from IPython import display
from unstructured.partition.pdf import partition_pdf
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.schema.messages import HumanMessage, SystemMessage
from langchain.schema.document import Document
from langchain.vectorstores import FAISS
from langchain.retrievers.multi_vector import MultiVectorRetriever




Enduring Hope. Daniel Deuschle







Edge computing environments consist of a wide range of hardware platforms, operating systems, network protocols, and communication standards, making interoperability, integration, and standardization complex challenges.Edge environments depend on a variety of devices with different capabilities, in contrast to centralized cloud data centers, which typically use standard hardware and software configurations.Given that each device may employ different communication protocols, data formats, and processing capabilities, this diversity makes it more difficult to collaborate, exchange data, and coordinate actions among devices.
As a result, ensuring cohesive interactions across this heterogeneous landscape is far more challenging than within standardized cloud settings.



Researchers are concentrating on creating standardized protocols, middleware, and frameworks that encourage interoperability among different edge devices in order to overcome these issues.Multi-protocol communication, cross-platform interoperability, and common APIs (Application Programming Interfaces) to simplify interactions between devices from various manufacturers are important development topics. Furthermore, efforts are focused on developing scalable edge platforms that don't require a lot of customisation and can handle a variety of devices and applications.In order to build a strong, flexible edge ecosystem that can meet the diverse needs of contemporary, distributed applications, these goals must be met.







American Heart Association (AHA) - Predoctoral Fellowship


Better Scientific Software (BSS) - Fellowship Program


Institute of Electrical and Electronic Engineers (IEEE) - Electron Devices Society (EDS) - Doctoral Student Fellowship




























